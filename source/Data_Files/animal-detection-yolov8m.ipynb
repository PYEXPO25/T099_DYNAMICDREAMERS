{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Animal Detection using YOLOv8 \n",
    "\n",
    "Table of contents:\n",
    "- Data processing (Custom dataset to YOLO format)\n",
    "- YOLO dataset configuration\n",
    "- Training and validating the model\n",
    "- Prediction visualization\n",
    "- Model export (tensorrt)\n",
    "- Model benchmark (tensorrt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOLOv8 can set up just by unstalling the `ultralytics` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T11:23:58.522657Z",
     "iopub.status.busy": "2023-05-28T11:23:58.522294Z",
     "iopub.status.idle": "2023-05-28T11:24:22.072944Z",
     "shell.execute_reply": "2023-05-28T11:24:22.071749Z",
     "shell.execute_reply.started": "2023-05-28T11:23:58.522628Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install ultralytics\n",
    "!yolo checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-05-28T11:24:22.076244Z",
     "iopub.status.busy": "2023-05-28T11:24:22.075812Z",
     "iopub.status.idle": "2023-05-28T11:24:24.134234Z",
     "shell.execute_reply": "2023-05-28T11:24:24.132997Z",
     "shell.execute_reply.started": "2023-05-28T11:24:22.076206Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from collections import defaultdict, Counter\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional, Iterable\n",
    "import yaml\n",
    "\n",
    "import cv2\n",
    "import plotly.express as px\n",
    "from plotly import subplots\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing\n",
    "\n",
    "### Original Dataset Structure\n",
    "\n",
    "Dataset structure is given in next format:\n",
    "\n",
    "```yaml\n",
    "animals-detection-images-dataset/\n",
    "    train/\n",
    "        {class1}/\n",
    "            Label/\n",
    "                {id_1}.txt\n",
    "                {id_2}.txt\n",
    "                ...\n",
    "            {id_1}.jpg\n",
    "            {id_2}.jpg\n",
    "            ...\n",
    "        {class2}/\n",
    "            ...\n",
    "        ...\n",
    "    test/\n",
    "    ...\n",
    "```\n",
    "\n",
    "In summary, the dataset is already split into `train` and `test` subsets. Each subset contains N different classes like \"Bear\", \"Brown bear\", \"Bull\", etc. Each class has its own folder in the (train/test) subset that contains list of images and label text files. Labels are inside `Label` directory while the images are in the root of the class directory.\n",
    "\n",
    "Annotations are in format: \"{label} {x_min} {y_min} {x_max} {y_max}\" where coordinates are not normalized.\n",
    "\n",
    "### Yolo Dataset Structure\n",
    "\n",
    "Dataset structure should be transformed to next format:\n",
    "\n",
    "```yaml\n",
    "yolo-dataset/\n",
    "    train/\n",
    "        images/\n",
    "            {id_1}.jpg\n",
    "            {id_2}.jpg\n",
    "            ...\n",
    "        labels/\n",
    "            {id_1}.txt\n",
    "            {id_2}.txt\n",
    "            ...\n",
    "        ...\n",
    "    test/\n",
    "    ...\n",
    "```\n",
    "\n",
    "Annotations should be in format: \"{label_index} {x_center} {y_center} {width} {height}\" where coordinates are normalized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T11:24:24.140260Z",
     "iopub.status.busy": "2023-05-28T11:24:24.139727Z",
     "iopub.status.idle": "2023-05-28T11:24:24.181961Z",
     "shell.execute_reply": "2023-05-28T11:24:24.180946Z",
     "shell.execute_reply.started": "2023-05-28T11:24:24.140216Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = '/kaggle/input/animals-detection-images-dataset'  # Path to source dataset\n",
    "MASTER_PATH = '/kaggle/working'  # Path where all outputs are stored (intermediate and final)\n",
    "DEBUG = False # Activete to run notebook faster\n",
    "CPU = False\n",
    "\n",
    "if not CPU:\n",
    "    assert torch.cuda.is_available(), 'CUDA not found!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset indexing and analysis\n",
    "\n",
    "Most of the work here is to convert custom Animal dataset to YOLO format. Two helper classes will be used here:\n",
    "- LookupTable: Creates vocabulary for class labels during;\n",
    "- AnimalToYOLODatasetAdapter: Support for Animal dataset parsing and converting it to YOLO dataset format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T11:24:24.185808Z",
     "iopub.status.busy": "2023-05-28T11:24:24.184873Z",
     "iopub.status.idle": "2023-05-28T11:24:24.199273Z",
     "shell.execute_reply": "2023-05-28T11:24:24.198387Z",
     "shell.execute_reply.started": "2023-05-28T11:24:24.185772Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class LookupTable:\n",
    "    \"\"\"Vocabulary - Label lookup table (token <-> index).\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        token_to_index: Optional[Dict[str, int]] = None,\n",
    "        unknown_token: str = '<unk>',\n",
    "        add_unknown_token: bool = True\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            token_to_index: Predefine token to index mappings.\n",
    "            unknown_token: Unknown token value.\n",
    "            add_unknown_token: Use unknown token.\n",
    "        \"\"\"\n",
    "        self._token_to_index = token_to_index\n",
    "        self._unknown_token = unknown_token\n",
    "        self._add_unknown_token = add_unknown_token\n",
    "\n",
    "        if self._token_to_index is None:\n",
    "            self._token_to_index = {}\n",
    "\n",
    "        if unknown_token not in self._token_to_index and add_unknown_token:\n",
    "            self._token_to_index[unknown_token] = len(self._token_to_index)\n",
    "\n",
    "        self._index_to_token = {v: k for k, v in self._token_to_index.items()}\n",
    "        self._next_index = len(self._token_to_index)\n",
    "\n",
    "    def add(self, token: str) -> int:\n",
    "        \"\"\"\n",
    "        Adds token to the lookup table if it does not already exist.\n",
    "        \n",
    "        Args:\n",
    "            token: Label (token)\n",
    "            \n",
    "        Returns:\n",
    "            label (token) index\n",
    "        \"\"\"\n",
    "        if token in self._token_to_index:\n",
    "            return self._token_to_index[token]\n",
    "\n",
    "        new_index = self._next_index\n",
    "        self._next_index += 1\n",
    "        self._token_to_index[token] = new_index\n",
    "        self._index_to_token[new_index] = token\n",
    "        return new_index\n",
    "\n",
    "    def lookup(self, token: str) -> int:\n",
    "        \"\"\"\n",
    "        Acquires token index if it exists in the table.\n",
    "        In case the token does not exist in the lookup table:\n",
    "            - and unknown token is used then unkown token index is returned;\n",
    "            - otherwise KeyError is raised\n",
    "            \n",
    "        Raises:\n",
    "            KeyError: Unknown token\n",
    "            \n",
    "        Returns:\n",
    "            label (token) index\n",
    "        \"\"\"\n",
    "        if token not in self._token_to_index and self._add_unknown_token:\n",
    "            return self._token_to_index[self._unknown_token]\n",
    "\n",
    "        return self._token_to_index[token]\n",
    "\n",
    "    def inverse_lookup(self, index: int) -> str:\n",
    "        \"\"\"\n",
    "        Inverse to `lookup`. Acquire token by index.\n",
    "        \n",
    "        Raises:\n",
    "            KeyError: Unknown index\n",
    "            \n",
    "        Returns:\n",
    "            label (token)\n",
    "        \"\"\"\n",
    "        return self._index_to_token[index]\n",
    "    \n",
    "    def __iter__(self) -> Iterable[Tuple[str, int]]:\n",
    "        for token, index in self._token_to_index.items():\n",
    "            yield token, index\n",
    "\n",
    "    def __getitem__(self, token: str) -> int:\n",
    "        return self.lookup(token)  # Alias for `lookup`\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._next_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T11:24:24.201406Z",
     "iopub.status.busy": "2023-05-28T11:24:24.200995Z",
     "iopub.status.idle": "2023-05-28T11:24:53.925824Z",
     "shell.execute_reply": "2023-05-28T11:24:53.924731Z",
     "shell.execute_reply.started": "2023-05-28T11:24:24.201374Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "DatasetIndex = Dict[str, Dict[str, List[str]]]\n",
    "DatasetStats = Dict[str, int]\n",
    "\n",
    "\n",
    "class AnimalToYOLODatasetAdapter:\n",
    "    \"\"\"Adapts custom animal dataset to YOLO format.\"\"\"\n",
    "    def __init__(self, path: str, label_filter: Optional[List[str]] = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            path: Path where dataset is stored\n",
    "            label_filter: Use specific set of labels (remove others from dataset)\n",
    "        \"\"\"\n",
    "        self._path = path\n",
    "        \n",
    "        self._index, self.label_stats, self.split_stats, self.label_lookup, self._size = \\\n",
    "            self._index_dataset(path, label_filter)\n",
    "        \n",
    "    @staticmethod\n",
    "    def _index_dataset(path: str, label_filter: Optional[List[str]] = None) \\\n",
    "        -> Tuple[DatasetIndex, DatasetStats, DatasetStats, LookupTable, int]:\n",
    "        \"\"\"\n",
    "        Creates datast index. Index is mapping (split -> label -> sample_id). \n",
    "        Input dataset format is given in previosly defined structure.\n",
    "\n",
    "        Args:\n",
    "            path: Dataset path\n",
    "            label_filter: Filter used labels\n",
    "\n",
    "        Returns:\n",
    "            Dataset index, Label stats, Split stats, dataset size\n",
    "        \"\"\"\n",
    "        index: DatasetIndex = defaultdict(dict)\n",
    "        label_stats: DatasetStats = Counter()\n",
    "        split_stats: DatasetStats = Counter()\n",
    "        lookup = LookupTable(add_unknown_token=False)\n",
    "        size = 0\n",
    "\n",
    "        splits = os.listdir(path)\n",
    "        for split in splits:        \n",
    "            split_path = os.path.join(path, split)\n",
    "            labels = os.listdir(split_path)\n",
    "            for label in tqdm(labels, desc=f'Indexing {split}', unit='sample'):\n",
    "                if label_filter is not None and label not in label_filter:\n",
    "                    continue\n",
    "                \n",
    "                label_path = os.path.join(split_path, label)\n",
    "                sample_ids = [Path(filename).stem for filename in os.listdir(label_path) \n",
    "                              if filename != 'Label' and filename.endswith('.jpg')]\n",
    "                annotations_path = os.path.join(label_path, 'Label')\n",
    "                annot_sample_ids = [Path(filename).stem for filename in os.listdir(annotations_path)\n",
    "                                    if filename.endswith('.txt')]\n",
    "                assert set(sample_ids) == set(annot_sample_ids), 'Image sample ids and annotation sample ids do not match'\n",
    "\n",
    "                # Update index, stats and lookup\n",
    "                index[split][label] = sample_ids\n",
    "                \n",
    "                n_samples = len(sample_ids)\n",
    "                label_stats[label] += n_samples\n",
    "                split_stats[split] += n_samples\n",
    "                size += n_samples\n",
    "                \n",
    "                lookup.add(label)\n",
    "\n",
    "        return dict(index), dict(label_stats), dict(split_stats), lookup, size\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return self._size\n",
    "    \n",
    "    @property\n",
    "    def labels(self) -> List[str]:\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            List of labels (classes) in lookup table\n",
    "        \"\"\"\n",
    "        return list(self.label_lookup)\n",
    "\n",
    "    @property\n",
    "    def n_labels(self) -> int:\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            Number of labels (classes) in lookup table\n",
    "        \"\"\"\n",
    "        return len(self.label_lookup)\n",
    "    \n",
    "    def get_random_samples(self, n: int, split: str = 'train') -> List[Tuple[str, str, str]]:\n",
    "        \"\"\"\n",
    "        Fetchen `n` random samples from dataset for chosen split.\n",
    "        \n",
    "        Args:\n",
    "            n: Number of samples\n",
    "            split: chosen split\n",
    "            \n",
    "        Returns:\n",
    "            List of tuples (split, label, sample_id)\n",
    "        \"\"\"\n",
    "        split_index = self._index[split]\n",
    "        label_names, _ = zip(*self.labels)\n",
    "        \n",
    "        result: List[Tuple[str, str, str]] = []\n",
    "        for i in range(n):\n",
    "            label = random.choice(label_names)\n",
    "            sample_ids = split_index[label]\n",
    "            sample_id = random.choice(sample_ids)\n",
    "            result.append((split, label, sample_id))\n",
    "            \n",
    "        return result\n",
    "    \n",
    "    def get_split_size(self, split: str) -> int:\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            Number of samples in split\n",
    "        \"\"\"\n",
    "        return self.split_stats[split]\n",
    "\n",
    "    def get_image_path(self, split: str, label: str, sample_id: str) -> str:\n",
    "        \"\"\"\n",
    "        Animal dataset image path convention.\n",
    "        \n",
    "        Args:\n",
    "            split: Split\n",
    "            label: Label (token)\n",
    "            sample_id: Sample id\n",
    "        \n",
    "        Returns:\n",
    "            Image path\n",
    "        \"\"\"\n",
    "        return os.path.join(self._path, split, label, f'{sample_id}.jpg')\n",
    "\n",
    "    def load_image(self, split: str, label: str, sample_id: str) -> str:\n",
    "        \"\"\"        \n",
    "        Args:\n",
    "            split: Split\n",
    "            label: Label (token)\n",
    "            sample_id: Sample id\n",
    "        \n",
    "        Returns:\n",
    "            Loaded image\n",
    "        \"\"\"\n",
    "        image_path = self.get_image_path(split, label, sample_id)\n",
    "        if not os.path.exists(image_path):\n",
    "            raise FileNotFound(f'Image \"{image_path}\" not found!')\n",
    "        return cv2.imread(image_path)\n",
    "\n",
    "    def get_annot_path(self, split: str, label: str, sample_id: str) -> str:\n",
    "        \"\"\"\n",
    "        Animal dataset annotation path convention.\n",
    "        \n",
    "        Args:\n",
    "            split: Split\n",
    "            label: Label (token)\n",
    "            sample_id: Sample id\n",
    "        \n",
    "        Returns:\n",
    "            Annotation path\n",
    "        \"\"\"\n",
    "        return os.path.join(self._path, split, label, 'Label', f'{sample_id}.txt')\n",
    "\n",
    "    def parse_annot(self, split: str, label: str, sample_id: str) \\\n",
    "        -> List[Tuple[str, float, float, float, float]]:\n",
    "        \"\"\"        \n",
    "        Parses annotation (ground truth) file.\n",
    "        \n",
    "        Args:\n",
    "            split: Split\n",
    "            label: Label (token)\n",
    "            sample_id: Sample id\n",
    "        \n",
    "        Returns:\n",
    "            Parsed annotations\n",
    "        \"\"\"\n",
    "        annot_path = self.get_annot_path(split, label, sample_id)\n",
    "        with open(annot_path, 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "        annots: List[Tuple[str, float, float, float, float]] = []\n",
    "        for l in lines:\n",
    "            items = l.split()\n",
    "            label_name = ' '.join(items[:-4])\n",
    "            coords = [float(v) for v in items[-4:]]\n",
    "            annots.append([label_name, *coords])\n",
    "        return annots\n",
    "    \n",
    "    def convert(self, path: str) -> None:\n",
    "        \"\"\"\n",
    "        Converts dataset tp YOLO format.\n",
    "        \n",
    "        Args:\n",
    "            path: Output path\n",
    "        \"\"\"\n",
    "        for split in self._index:\n",
    "            split_path = os.path.join(path, split)\n",
    "            images_path = os.path.join(split_path, 'images')\n",
    "            labels_path = os.path.join(split_path, 'labels')\n",
    "            Path(images_path).mkdir(parents=True, exist_ok=True)\n",
    "            Path(labels_path).mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            for label, sample_ids in tqdm(self._index[split].items(), desc='Converting to Yolo format', total=len(self._index[split])):\n",
    "                assert len(sample_ids) == len(set(sample_ids))\n",
    "                for sample_id in sample_ids:\n",
    "                    image_path = self.get_image_path(split, label, sample_id)\n",
    "                    new_image_path = os.path.join(images_path, f'{sample_id}.jpg')\n",
    "                    annots = self.parse_annot(split, label, sample_id)\n",
    "                    new_annot_path = os.path.join(labels_path, f'{sample_id}.txt')\n",
    "                    \n",
    "                    # Image needs to be loaded in order to read width and height\n",
    "                    # which are required for coordinate normalization\n",
    "                    image = self.load_image(split, label, sample_id)\n",
    "                    h, w, _ = image.shape\n",
    "                    \n",
    "                    # Conversion\n",
    "                    converted_annot: List[Tuple[int, float, float, float, float]] = []\n",
    "                    for label, x_min, y_min, x_max, y_max in annots:\n",
    "                        label_index = self.label_lookup[label]\n",
    "                        x_center = (x_min + x_max) / (2 * w)\n",
    "                        y_center = (y_min + y_max) / (2 * h)\n",
    "                        width = (x_max - x_min) / w\n",
    "                        height = (y_max - y_min) / h\n",
    "                        \n",
    "                        converted_annot.append((label_index, x_center, y_center, width, height))\n",
    "                        \n",
    "                    # Save data\n",
    "                    with open(new_annot_path, 'a', encoding='utf-8') as f:\n",
    "                        converted_annot_lines = [' '.join([str(v) for v in row]) for row in converted_annot]\n",
    "                        f.write('\\n'.join(converted_annot_lines))\n",
    "                        f.write('\\n')\n",
    "                        \n",
    "                    if not os.path.exists(new_image_path):  \n",
    "                        shutil.copy(image_path, new_image_path)\n",
    "\n",
    "\n",
    "adapter = AnimalToYOLODatasetAdapter(\n",
    "    path=DATASET_PATH, \n",
    "    label_filter=['Horse'] if DEBUG else None\n",
    ")\n",
    "\n",
    "print(f'Total number of samples in the dataset is {len(adapter)}.')\n",
    "print(f'Total number of classes in the dataset is {adapter.n_labels}.')\n",
    "print(f'Train dataset size is {adapter.get_split_size(\"train\")} (images). Test dataset size is {adapter.get_split_size(\"test\")} (images)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T11:24:53.927773Z",
     "iopub.status.busy": "2023-05-28T11:24:53.927391Z",
     "iopub.status.idle": "2023-05-28T11:24:55.198136Z",
     "shell.execute_reply": "2023-05-28T11:24:55.197273Z",
     "shell.execute_reply.started": "2023-05-28T11:24:53.927740Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig = px.histogram(x=list(adapter.label_stats.keys()), y=list(adapter.label_stats.values())) \\\n",
    "        .update_layout(xaxis_title=\"Class\", yaxis_title=\"Class size\", xaxis={'categoryorder':'total descending'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the dataset is very unbalanced. Next step is to visualize few samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T11:24:55.200912Z",
     "iopub.status.busy": "2023-05-28T11:24:55.199490Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def visualize_samples(\n",
    "    adapter: AnimalToYOLODatasetAdapter,\n",
    "    n_rows: int,\n",
    "    n_cols: int,\n",
    "    bbox_color: Tuple[int, int, int] = (255, 0, 0),  # RBG - RED\n",
    "    model: Optional[YOLO] = None\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Visualizes image sample with ground truths and (optionally) model predictions.\n",
    "    Number of images is equal to product of `n_rows` and `n_cols`\n",
    "    \n",
    "    Args:\n",
    "        adapter: Animal dataset to YOLO adapter\n",
    "        n_rows: Number of rows in image matrix\n",
    "        n_cols: Number of cols in image matrix\n",
    "        bbox_color: Ground truth bbox color\n",
    "        model: Model to generate prediction for given images\n",
    "    \"\"\"\n",
    "    n: int = n_rows * n_cols\n",
    "    \n",
    "    viz_samples = adapter.get_random_samples(n)\n",
    "    fig = subplots.make_subplots(rows=n_rows, cols=n_cols)\n",
    "    for plot_index, (split, label, sample_id) in enumerate(viz_samples):\n",
    "        row = plot_index // n_cols + 1\n",
    "        col = plot_index % n_cols + 1\n",
    "        image = adapter.load_image(split, label, sample_id)\n",
    "        label_index = adapter.label_lookup.lookup(label)\n",
    "        \n",
    "        # Visualize ground truth\n",
    "        for _, x_min, y_min, x_max, y_max in adapter.parse_annot(split, label, sample_id):\n",
    "            x_min, y_min, x_max, y_max = [int(v) for v in [x_min, y_min, x_max, y_max]]\n",
    "            labek_text = f'{label} ({label_index})'\n",
    "            image = cv2.rectangle(image, (x_min, y_min), (x_max, y_max), color=bbox_color, thickness=4)\n",
    "            image = cv2.putText(image, label, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 2, bbox_color, 3)\n",
    "            \n",
    "        if model is not None:\n",
    "            # Visualize model predictions\n",
    "            prediction = model.predict([image], imgsz=512, conf=0.3)\n",
    "            for p in prediction:\n",
    "                image = p.plot()\n",
    "            \n",
    "        subfig = px.imshow(image)\n",
    "        fig.add_trace(subfig.data[0], row=row, col=col)\n",
    "\n",
    "    fig = fig.update_xaxes(showticklabels=False)\n",
    "    fig = fig.update_yaxes(showticklabels=False)\n",
    "    fig = fig.update_layout(\n",
    "        autosize=False,\n",
    "        width=1200,\n",
    "        height=600\n",
    "    )\n",
    "    fig.show()\n",
    "    \n",
    "visualize_samples(adapter, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.idle": "2023-05-28T11:39:31.362806Z",
     "shell.execute_reply": "2023-05-28T11:39:31.361745Z",
     "shell.execute_reply.started": "2023-05-28T11:24:55.985940Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "adapter.convert(MASTER_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO Dataset configuration\n",
    "\n",
    "Defining dataset configuration is simple once the dataset is converted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T11:48:45.931657Z",
     "iopub.status.busy": "2023-05-28T11:48:45.931267Z",
     "iopub.status.idle": "2023-05-28T11:48:45.949521Z",
     "shell.execute_reply": "2023-05-28T11:48:45.948693Z",
     "shell.execute_reply.started": "2023-05-28T11:48:45.931629Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class_names = [name for name, _ in adapter.label_lookup]\n",
    "config = {\n",
    "    'path': MASTER_PATH,\n",
    "    'train': 'train/images',\n",
    "    'val': 'test/images',\n",
    "    'nc': len(adapter.label_lookup),  # number of classes\n",
    "    'names': class_names\n",
    "}\n",
    "\n",
    "config_path = os.path.join(MASTER_PATH, 'config.yaml')\n",
    "with open(config_path, 'w', encoding='utf-8') as f:\n",
    "    yaml.dump(config, f)\n",
    "\n",
    "print(yaml.dump(config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and validating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T11:48:52.681648Z",
     "iopub.status.busy": "2023-05-28T11:48:52.681286Z",
     "iopub.status.idle": "2023-05-28T13:06:08.468008Z",
     "shell.execute_reply": "2023-05-28T13:06:08.466576Z",
     "shell.execute_reply.started": "2023-05-28T11:48:52.681620Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create a new YOLO model from scratch\n",
    "model = YOLO('yolov8m.yaml')\n",
    "\n",
    "# Load a pretrained YOLO model (recommended for training)\n",
    "model = YOLO('yolov8m.pt')\n",
    "\n",
    "# Train the model using the processed dataset\n",
    "results = model.train(\n",
    "    data='config.yaml', \n",
    "    epochs=5 if not DEBUG else 1,\n",
    "    optimizer='Adam',\n",
    "    val=True,\n",
    "    batch=64,\n",
    "    imgsz=640,\n",
    "    device=[0] if not CPU else 'cpu',\n",
    "    lr0=0.001,\n",
    "    lrf=0.0005\n",
    ")\n",
    "\n",
    "# Evaluate the model's performance on the validation set\n",
    "results = model.val()\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is only trained for 5 epochs. With increased number of epochs to 20+ it is expected to have mAP50 0.60+ and mAP50-95 is 0.50+ which is decent. Full model training is skipped here because of Kaggle notebook time constraints. \n",
    "\n",
    "Checkpoint to the 0.619 mAP50 model (`YOLOv8-n-baseline`) can be found [here](https://drive.google.com/drive/folders/1RQor80VZ_urxmoJNQwF0j7DD4Ow7yDQI). This model was trained for 100 epochs for 4 hours on `RTX3070`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Visualization\n",
    "\n",
    "For the model prediction visualization the `visualize_samples` helper function is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T13:18:27.663195Z",
     "iopub.status.busy": "2023-05-28T13:18:27.662750Z",
     "iopub.status.idle": "2023-05-28T13:18:29.392776Z",
     "shell.execute_reply": "2023-05-28T13:18:29.391208Z",
     "shell.execute_reply.started": "2023-05-28T13:18:27.663155Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "visualize_samples(adapter, 2, 3, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "- [YOLOv8 documenation](https://docs.ultralytics.com/)\n",
    "- [Aircraft Detection with YOLOv8](https://www.kaggle.com/code/jeffaudi/aircraft-detection-with-yolov8)\n",
    "- [Kaggle dataset](https://www.kaggle.com/code/momiradzemovic/animal-detection-yolov8/input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
